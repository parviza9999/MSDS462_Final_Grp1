{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parviza9999/MSDS462_Final_Grp1/blob/main/FER2013_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After building and saving the model and weights from running the python program found at this link->  https://colab.research.google.com/drive/1sxGibCl39FiApFPvGuoqPR4_hhMTgXJ5?usp=sharing\n",
        "##We need to run this code to activate the camera on edge device running Pyhon. This file can be saved as .py script and run from the command prompt.\n",
        "\n",
        "## Following three files must be present in the same directory where the script will be run:\n",
        "#1) model_fer.json\n",
        "#2) model_fer.h5\n",
        "#3) haarcascade_frontalface_default.xml"
      ],
      "metadata": {
        "id": "HBYM_Mt9Jfic"
      },
      "id": "HBYM_Mt9Jfic"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ae52b7",
      "metadata": {
        "id": "48ae52b7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ec0cd5",
      "metadata": {
        "id": "56ec0cd5",
        "outputId": "5dbae807-1edf-4e08-bdc7-b317d0976934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function destroyAllWindows>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load model\n",
        "model = model_from_json(open(\"model_fer.json\", \"r\").read())\n",
        "#load weights\n",
        "model.load_weights('model_fer.h5')\n",
        "\n",
        "\n",
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
        "    if not ret:\n",
        "        continue\n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
        "\n",
        "\n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "        img_pixels = image.img_to_array(roi_gray)\n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "        img_pixels /= 255\n",
        "\n",
        "        predictions = model.predict(img_pixels)\n",
        "\n",
        "        #find max indexed array\n",
        "        max_index = np.argmax(predictions[0])\n",
        "\n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "        predicted_emotion = emotions[max_index]\n",
        "\n",
        "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))\n",
        "    cv2.imshow('Face Emotion Recognition',resized_img)\n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Link to Gdrive -> https://docs.google.com/document/d/1EV5huN4QH7o-pn0F4hFl7nZT7wJkHx1AKqEXulWQhvc/edit?usp=sharing\n",
        "\n",
        "# Github -> https://github.com/parviza9999/MSDS462_Final_Grp1/blob/main/MSDS462_Final_Report_Group1.pdf\n"
      ],
      "metadata": {
        "id": "PMStC6nPNpTJ"
      },
      "id": "PMStC6nPNpTJ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "FER2013_Script.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}